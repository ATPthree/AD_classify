# 总览
该方法从AD对话的ASR转录文本，提取特征，然后用机器学习方法2分类，准确率大概是0.6-0.7左右。
但我的对话系统没有这样的转录文本啊，这都是人工转录的。我要怎么做呢？

1、做一个AI转录，做到相似的标注（有无小论文？可以看看相关工作,如果没有，是不是可以单独做一个work？）
2、公平比较，baseline方法就是语音，我们对话系统也是语音，端到端2分类。
    或者，baseline方法 是语音 + AI自动ASR方法f，我们的方法是 自动化对话系统获取的语音对话 + AI自动ASR方法，端到端2分类。


# 数据预处理（data_process.py 和 data_process_withPauses.py）
data_process.py：从原始的对话记录中移除所有 CHAT 标签，仅保留受试者的对话内容。
data_process_withPauses.py：除了保留对话，还保留了 停顿信息，这对于提取语音特征（如语句的停顿时间）可能非常重要。

### 脚本功能概述
处理原始对话数据：通过逐行读取文件，移除不必要的标签、噪声和格式内容，提取有效的对话内容。
计算停顿和填充词：识别并统计停顿符号（如 (.)，(..)，(...)）和填充词（如 +...），这些是语言学分析中的重要特征。
保存处理后的数据：提取的特征被保存在一个 CSV 文件中，包含每个对话的详细信息（如停顿、无效单词、重复等）。

### 调试记录
C:\Users\lxq717machine\Desktop\DementiaBank\Pitt\project1\AutomatedDementiaDiagnosis-master\data_process_withPauses.py
```
     age = content[6].split(':')[1].split('|')[3][:-1]
     gender = content[6].split(':')[1].split('|')[4]
     MMSE = content[6].split(':')[1].split('|')[8]
     category = content[6].split(':')[1].split('|')[5]
     metadata.loc[idx] = [file, age, gender, \
                         MMSE, count_pause[0], count_pause[1], count_pause[2], 
                         count_misc[0], count_misc[1], 
                         count_misc[2], category, dialogue]
```
修改：content[5] >> content[6]

# feature_extract_new.py

下载nltk_data

这个脚本从预处理后的元数据中提取特征。输入文件是经过预处理的 csv 文件，这些文件包含了受试者的对话数据及其停顿信息。

### 输入参数：
--file_path：预处理过的元数据文件路径。
--file_path2：包含停顿信息的预处理元数据文件路径，用于计算 Mean Length Utterance (MLU)，即每个发话单元的平均长度。
特征提取是机器学习模型训练的基础，它将原始数据转化为可以输入到机器学习算法中的格式。


### 主要功能与流程
词性标注和句法分析：

词性（POS）标注：分析文本中的每个词的语法角色，例如名词、动词、形容词等。
使用nltk进行词性标注和短语分析，计算诸如名词短语（NP）和动词短语（VP）的频率。
计算每个文件中的TTR（类型-标记比率），这可以反映出对话的词汇多样性。
语法特征提取：

使用词汇词根（Lemmatization）：将动词还原为词根形式（例如将"running"还原为"run"）。
使用自定义的语法规则，例如识别名词短语（NP）、动词短语（VP）等，提取与语法结构相关的信息。
计算短语频率，例如名词短语和动词短语的出现次数。
语义特征提取：

计算每个文本中提到的概念数量，例如“cookie”，“mother”，“boy”等。
通过文本中提到的特定关键词来衡量文本的语义内容。
声学特征提取：

计算文本中的停顿数量（如：1pause1、2pause2、3pause3），以及无法理解的单词、重复词等声学特征。
计算多个复杂的统计特征：

TTR（词汇多样性比率）：即类型词数与标记词数的比率。
Honore’s statistic：计算文本的词汇丰富度。
平均句子长度（MLU）：根据文本中的标点符号（如句号、问号等）和停顿来计算。
自动阅读指数（ARI） 和 Coleman-Liau指数（CLI）：这些是基于字符数、单词数、句子数来估算文本的阅读难度的公式。
词到句子的比率：表示每个句子中包含多少个词。
相似度计算：

计算文本的词性分布相似度（使用余弦相似度），与全局的词性分布向量进行比较，以度量文本之间的相似度。
数据标签：

将每个样本的数据分为Control和Dementia类别，以便后续用于分类任务。
根据给定的MMSE或DEM类型进行分类。
输出特征集：

提取的特征会被存储到feature_set.csv文件中。根据任务类型，可能会输出不同类型的特征文件：
feature_set_MMSE.csv：用于MMSE评分预测。
feature_set_dem.csv：用于认知障碍（如Dementia vs. Control）的分类任务。
主要的函数和步骤
similarity()：

计算文本中的词性分布向量，并与全局的POS（词性）分布进行余弦相似度计算，评估文本与全局词性分布的相似性。
get_tag_info()：

提取每个文本的各种语言学特征：包括词性标注、短语提取、词汇的词根化、名词和动词的频率计算等。
还包括计算文本的阅读难度指数、停顿计数、重复词计数等声学特征。
main()：

读取metadata_allvisits.csv和metadata_withPauses.csv文件，准备数据进行特征提取。
调用get_tag_info()函数提取特征，并根据任务类型输出到相应的CSV文件。



### 特征说明
语言学特征：

TTR：表示语言多样性的指数，越高说明文本使用了更多的独特词汇。
MLU：反映了说话者的句子复杂度，长时间的停顿可能意味着复杂或困惑的表达。
POS标签：分析文本中每种词性的分布，能够反映出对话的语法特征。
NP和VP频率：反映出名词短语和动词短语在对话中的频率，能够帮助理解对话的语法结构。
语义特征：

概念提及数量：测量文本中提到特定概念的数量，能够反映对话的内容深度。
停顿和无法理解的词：这些声学特征能够提供一些关于说话者流畅度和清晰度的线索。
统计特征：

阅读指数：如ARI和CLI等指数，能够反映文本的可读性或难度。


# model.py
LR, DT, SVM, RF

这个脚本用于训练和预测模型。它支持多种机器学习算法，用户可以选择不同的模型来进行痴呆症分类或 MMSE 预测。

输入参数：
--model：选择使用的模型，支持：
LR：逻辑回归（Logistic Regression）
DT：决策树（Decision Tree）
RF：随机森林（Random Forest）
SVM：支持向量机（Support Vector Machine）
--type：选择任务类型：
DEM：痴呆症分类任务
MMSE：MMSE 分类任务
--file_path：特征集的 CSV 文件路径
使用这个脚本时，你可以根据需求选择不同的分类问题（痴呆症分类或 MMSE 分类）以及不同的模型进行训练和预测。

### 运行model.py
```bash
cd C:\Users\lxq717machine\Desktop\DementiaBank\Pitt\project1\AutomatedDementiaDiagnosis-master
python model.py --model LR --type DEM 
```

```bash
cd C:\Users\lxq717machine\Desktop\DementiaBank\Pitt\project1\AutomatedDementiaDiagnosis-master
python model.py --model DT --type DEM 
```

```bash
cd C:\Users\lxq717machine\Desktop\DementiaBank\Pitt\project1\AutomatedDementiaDiagnosis-master
python model.py --model SVM --type DEM 
```

```bash
cd C:\Users\lxq717machine\Desktop\DementiaBank\Pitt\project1\AutomatedDementiaDiagnosis-master
python model.py --model RF --type DEM 
```



### 结果
#### LR
```
C:\Users\lxq717machine\anaconda3\envs\metagpt\python.exe C:\Users\lxq717machine\Desktop\DementiaBank\Pitt\project1\AutomatedDementiaDiagnosis-master\model.py 
0.733509513742072
Test accuracy for model: 0.7818181818181819

F1-score: [0.77777778 0.78571429]
              precision    recall  f1-score   support

           0       0.84      0.72      0.78        58
           1       0.73      0.85      0.79        52

    accuracy                           0.78       110
   macro avg       0.79      0.79      0.78       110
weighted avg       0.79      0.78      0.78       110
进程已结束，退出代码为 0

```

#### DT
```
C:\Users\lxq717machine\anaconda3\envs\metagpt\python.exe C:\Users\lxq717machine\Desktop\DementiaBank\Pitt\project1\AutomatedDementiaDiagnosis-master\model.py 
0.6288054968287526
Test accuracy for model: 0.7090909090909091

F1-score: [0.7037037  0.71428571]
              precision    recall  f1-score   support

           0       0.76      0.66      0.70        58
           1       0.67      0.77      0.71        52

    accuracy                           0.71       110
   macro avg       0.71      0.71      0.71       110
weighted avg       0.72      0.71      0.71       110


进程已结束，退出代码为 0

```
#### SVM
```
C:\Users\lxq717machine\anaconda3\envs\metagpt\python.exe C:\Users\lxq717machine\Desktop\DementiaBank\Pitt\project1\AutomatedDementiaDiagnosis-master\model.py 
0.5785940803382664
Test accuracy for model: 0.4727272727272727

F1-score: [0.         0.64197531]
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.47      1.00      0.64        52

    accuracy                           0.47       110
   macro avg       0.24      0.50      0.32       110
weighted avg       0.22      0.47      0.30       110


进程已结束，退出代码为 0
```
#### RF
```
C:\Users\lxq717machine\anaconda3\envs\metagpt\python.exe C:\Users\lxq717machine\Desktop\DementiaBank\Pitt\project1\AutomatedDementiaDiagnosis-master\model.py 
0.651585623678647
Test accuracy for model: 0.7

F1-score: [0.7079646  0.69158879]
              precision    recall  f1-score   support

           0       0.73      0.69      0.71        58
           1       0.67      0.71      0.69        52

    accuracy                           0.70       110
   macro avg       0.70      0.70      0.70       110
weighted avg       0.70      0.70      0.70       110


进程已结束，退出代码为 0

```

#### 代码分析
数据划分：80% 作为训练集，20% 作为测试集。使用 StratifiedKFold 对训练集进行 10 折交叉验证，确保每一折的类别分布一致。
模型训练与评估：根据所选的模型（RF、SVM、DT 等），对训练数据进行训练，并通过交叉验证评估模型的性能。每一折的准确率被记录并计算其平均值。
模型测试：使用测试集评估最终模型，计算测试集上的准确率（accuracy）、F1 分数和其他分类指标（classification_report）。

exploratory_analysis 函数用于执行一些基础的数据探索性分析。通过箱形图（boxplot）比较不同类别（Control 和 AD）在多个特征（如 ARI, CLI, MMSE 等）上的分布。
还计算了各个特征与类别之间的皮尔逊相关系数，帮助分析特征与类别之间的相关性。
（没有调用，可额外调用）

# 结果汇总
| 模型 | 准确率 | F1 分数 | 特异性 | 敏感性 |
|-------|----------|-----------|--------|--------|
| 逻辑回归（LR） | 78.2% | 0.78 | 72% | 85% |
| 决策树（DT） | 70.9% | 0.71 | 66% | 77% |
| 支持向量机（SVM） | 47.3% | 0.64 | 0% | 100% |
| 随机森林（RF） | 70.0% | 0.69 | 69% | 71% |

注意，数据处理：，Control 类别的数据在 feature_set_dem.csv 中会被标记为 0。而 Dementia 类别的数据会被标记为 1。
在使用逻辑回归（LR）进行二分类时，Dementia 是正类，Control 是负类。
# 数据分析（word_cloud_gen.py）
该脚本用于生成 词云，可以帮助可视化健康对照组和痴呆组之间的词汇差异。词云是通过分析对话中的常见词汇来创建的，有助于直观地了解两组之间的语言模式差异。

# END


